# ğŸ”— MVP de Engenharia de Dados - Rastreador de Criptoativos

Este projeto Ã© o MVP (MÃ­nimo Produto ViÃ¡vel) desenvolvido para a disciplina de Engenharia de Dados da pÃ³s-graduaÃ§Ã£o em CiÃªncia de Dados e Analitycs.

O objetivo Ã© construir um pipeline completo de coleta, modelagem, carga e anÃ¡lise de dados de criptoativos, utilizando a nuvem AWS e ferramentas open source.

---

## ğŸš€ Objetivo

O objetivo deste projeto Ã© desenvolver um pipeline de engenharia de dados voltado para o rastreamento e anÃ¡lise de criptoativos. O sistema serÃ¡ responsÃ¡vel por coletar dados histÃ³ricos de preÃ§os de diferentes ativos digitais por meio da API pÃºblica da CoinGecko, armazenÃ¡-los na nuvem (AWS) e estruturÃ¡-los de forma que possam ser utilizados em anÃ¡lises futuras.

Inicialmente, o foco estarÃ¡ na construÃ§Ã£o da infraestrutura de coleta, modelagem, carga e anÃ¡lise de dados. Em etapas futuras, os dados serÃ£o reutilizados em projetos de ciÃªncia de dados para geraÃ§Ã£o de insights e modelos preditivos voltados Ã  identificaÃ§Ã£o de oportunidades de entrada no mercado.

### ğŸ¯ Problema a ser resolvido

**Como identificar criptoativos com comportamentos que possam indicar oportunidades de investimento, utilizando dados histÃ³ricos de preÃ§os e volume?**

### â“ Perguntas que o projeto pretende responder

1. Quais criptoativos apresentam maior volatilidade nos Ãºltimos perÃ­odos?
2. Quais ativos tiveram os maiores crescimentos em curtos intervalos de tempo?
3. Existe algum padrÃ£o de comportamento de preÃ§os em determinados dias da semana ou do mÃªs?
4. Ã‰ possÃ­vel identificar agrupamentos (clusters) de ativos com comportamentos semelhantes?
5. Como o volume de negociaÃ§Ã£o influencia a variaÃ§Ã£o de preÃ§os dos ativos?
6. Como os criptoativos se comportam em relaÃ§Ã£o Ã  fatores externos, como por exemplo, fatos polÃ­ticos.

> âš ï¸ **ObservaÃ§Ã£o:** Este trabalho se concentra na construÃ§Ã£o da fundaÃ§Ã£o de dados (engenharia), sendo a parte de anÃ¡lises preditivas e identificaÃ§Ã£o automatizada de oportunidades explorada futuramente em disciplinas de ciÃªncia de dados.

---

## ğŸ”§ Tecnologias Utilizadas
AWS Lambda â€“ Coleta automatizada diÃ¡ria

AWS S3 â€“ Armazenamento de dados brutos

Databricks â€“ Plataforma principal para processamento de dados, incluindo:

Delta Lake â€“ Armazenamento e versionamento de dados

Autoloader â€“ IngestÃ£o automÃ¡tica de dados

Structured Streaming â€“ Processamento de dados em tempo real

Unity Catalog â€“ GovernanÃ§a e catÃ¡logo de dados

Python â€“ requests, pandas, entre outras bibliotecas

CoinGecko API â€“ Fonte dos dados de criptoativos

---

## ğŸ—‚ï¸ Estrutura do Projeto

```plaintext
.
â”œâ”€â”€ analise/                # Notebooks e documentos de anÃ¡lise de dados
â”‚   â”œâ”€â”€ analise_qualidade_dados.md
â”‚   â”œâ”€â”€ analise_qualidade_silver.ipynb
â”‚   â””â”€â”€ discussao_resultado.md
â”œâ”€â”€ avaliacao/              # AutoavaliaÃ§Ã£o e materiais relacionados
â”‚   â””â”€â”€ autoavaliacao.md
â”œâ”€â”€ catalogo_de_dados/      # CatÃ¡logo de dados com descriÃ§Ã£o dos campos e domÃ­nios
â”‚   â”œâ”€â”€ catalogo_de_dados_bronze.md
â”‚   â””â”€â”€ catalogo_de_dados_silver.md.ipynb
â”œâ”€â”€ crypto_data_extractor/  # CÃ³digo da funÃ§Ã£o Lambda para coleta dos dados
â”‚   â”œâ”€â”€ lambda_layer
â”‚   â”‚   â””â”€â”€ lambda_dependencies_layer.zip
â”‚   â”œâ”€â”€ src
â”‚   â”‚   â”œâ”€â”€ crawler
â”‚   â”‚   â”‚   â””â”€â”€ fetcher.py
â”‚   â”‚   â””â”€â”€ __init__.py 
â”‚   â”œâ”€â”€ lambda_function_code.zip
â”‚   â””â”€â”€ requirements.txt 
â”œâ”€â”€ docs/                   # prints
â”œâ”€â”€ lakehouse/              # Notebooks e scripts relacionados ao Databricks
â”‚   â”œâ”€â”€ 01.bronze
â”‚   â”‚   â”œâ”€â”€ processaDiario.ipynb
â”‚   â”‚   â””â”€â”€ processaHistorico.ipynb
â”‚   â”œâ”€â”€ 02.silver
â”‚   â”‚   â””â”€â”€ processamentoDominioCripto.ipynb
â”‚   â””â”€â”€ 03.gold
â”‚       â””â”€â”€ visoesDominioCripto.ipynb
â””â”€â”€ README.md               # Este arquivo
```

---

## ğŸ“… FrequÃªncia de Coleta

- DiÃ¡ria (via AWS Lambda)
- Endpoints utilizados: `/coins/{id}/market_chart`, entre outros da [CoinGecko API](https://www.coingecko.com/en/api)

---

## ğŸ§ª Como Executar Localmente

1. Clone o repositÃ³rio:

```bash
git clone https://github.com/douglas-engenheirodedados/mvpEngDadosPosPuc
cd crypto_data_extractor
```

2. Crie um ambiente virtual e instale as dependÃªncias:

```bash
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate no Windows
pip install -r requirements.txt
```

3. Execute o script de coleta manualmente (opcional):

```bash
python src/crawler/fetcher #adequar os endpoints da API e S3 para o seu contexto.
```

---

## ğŸ§¾ LicenÃ§a dos Dados

Este projeto utiliza dados pÃºblicos disponibilizados pela [CoinGecko API](https://www.coingecko.com/en/api), sob seus termos de uso.

---

## âœ… Checklist para Entrega

âœ… Objetivo e perguntas de negÃ³cio definidos

âœ… Coleta automÃ¡tica implementada

âœ… Modelagem e catÃ¡logo de dados

âœ… Pipeline de dados com Databricks

âœ… AnÃ¡lise de dados (qualidade + soluÃ§Ã£o)

âœ… AutoavaliaÃ§Ã£o escrita

âœ… EvidÃªncias (prints e/ou vÃ­deos) adicionadas em docs/

âœ… CÃ³digo hospedado em repositÃ³rio pÃºblico do GitHub

---

## âœï¸ Autor

- **Nome:** Douglas Littig
- **Curso:** PÃ³s-graduaÃ§Ã£o em CiÃªncia de Dados e Analitycs