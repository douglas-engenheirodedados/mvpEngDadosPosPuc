# ğŸ”— MVP de Engenharia de Dados - Rastreador de Criptoativos

Este projeto Ã© o MVP (MÃ­nimo Produto ViÃ¡vel) desenvolvido para a disciplina de Engenharia de Dados da pÃ³s-graduaÃ§Ã£o em CiÃªncia de Dados e Analitycs.

O objetivo Ã© construir um pipeline completo de coleta, modelagem, carga e anÃ¡lise de dados de criptoativos, utilizando a nuvem AWS e ferramentas open source.

---

## ğŸš€ Objetivo

O objetivo deste projeto Ã© desenvolver um pipeline de engenharia de dados voltado para o rastreamento e anÃ¡lise de criptoativos. O sistema serÃ¡ responsÃ¡vel por coletar dados histÃ³ricos de preÃ§os de diferentes ativos digitais por meio da API pÃºblica da CoinGecko, armazenÃ¡-los na nuvem (AWS) e estruturÃ¡-los de forma que possam ser utilizados em anÃ¡lises futuras.

Inicialmente, o foco estarÃ¡ na construÃ§Ã£o da infraestrutura de coleta, modelagem, carga e anÃ¡lise de dados. Em etapas futuras, os dados serÃ£o reutilizados em projetos de ciÃªncia de dados para geraÃ§Ã£o de insights e modelos preditivos voltados Ã  identificaÃ§Ã£o de oportunidades de entrada no mercado.

### ğŸ¯ Problema a ser resolvido

**Como identificar criptoativos com comportamentos que possam indicar oportunidades de investimento, utilizando dados histÃ³ricos de preÃ§os e volume?**

### â“ Perguntas que o projeto respondeu
Durante a construÃ§Ã£o do MVP, com os dados organizados e estruturados na arquitetura Lakehouse, foram exploradas as seguintes perguntas de negÃ³cio:

Qual o ativo com maior preÃ§o mÃ©dio no perÃ­odo?

Qual o ativo com maior desvio padrÃ£o de preÃ§o?

Qual ativo apresentou o maior volume mÃ©dio negociado?

Existe alguma correlaÃ§Ã£o entre volume negociado e preÃ§o mÃ©dio?

Quais as estatÃ­sticas bÃ¡sicas dos ativos disponÃ­veis (mÃ­nimo, mÃ¡ximo, total de registros, etc)?

âš ï¸ ObservaÃ§Ã£o: Esta etapa focou na exploraÃ§Ã£o inicial dos dados com base nas informaÃ§Ãµes coletadas e tratadas. AnÃ¡lises mais avanÃ§adas (como prediÃ§Ãµes, agrupamentos ou padrÃµes comportamentais) poderÃ£o ser conduzidas futuramente, em disciplinas voltadas para ciÃªncia de dados.

> âš ï¸ **ObservaÃ§Ã£o:** Este trabalho se concentra na construÃ§Ã£o da fundaÃ§Ã£o de dados (engenharia), sendo a parte de anÃ¡lises preditivas e identificaÃ§Ã£o automatizada de oportunidades explorada futuramente em disciplinas de ciÃªncia de dados.

---

## ğŸ”§ Tecnologias Utilizadas
AWS Lambda â€“ Coleta automatizada diÃ¡ria

AWS S3 â€“ Armazenamento de dados brutos

Databricks â€“ Plataforma principal para processamento de dados, incluindo:

Delta Lake â€“ Armazenamento e versionamento de dados

Autoloader â€“ IngestÃ£o automÃ¡tica de dados

Structured Streaming â€“ Processamento de dados em tempo real

Unity Catalog â€“ GovernanÃ§a e catÃ¡logo de dados

Python â€“ requests, pandas, entre outras bibliotecas

CoinGecko API â€“ Fonte dos dados de criptoativos

---

## ğŸ—‚ï¸ Estrutura do Projeto

```plaintext
.
â”œâ”€â”€ analise/                # Notebooks e documentos de anÃ¡lise de dados
â”‚   â”œâ”€â”€ analise_qualidade_dados.md           # Documento descritivo da anÃ¡lise de qualidade dos dados
â”‚   â”œâ”€â”€ analise_qualidade_silver.ipynb       # Notebook com os cÃ³digos utilizados na anÃ¡lise de qualidade
â”‚   â””â”€â”€ discussao_resultado.md               # DiscussÃ£o dos resultados obtidos com base nas perguntas do projeto
â”œâ”€â”€ avaliacao/              # AutoavaliaÃ§Ã£o e materiais relacionados
â”‚   â””â”€â”€ autoavaliacao.md                     # Documento de autoavaliaÃ§Ã£o com reflexÃµes sobre o projeto
â”œâ”€â”€ catalogo_de_dados/      # CatÃ¡logo de dados com descriÃ§Ã£o dos campos e domÃ­nios
â”‚   â”œâ”€â”€ catalogo_de_dados_bronze.md          # DescriÃ§Ã£o da estrutura de dados na camada Bronze
â”‚   â””â”€â”€ catalogo_de_dados_silver.md.ipynb    # Notebook com descriÃ§Ã£o detalhada da camada Silver
â”œâ”€â”€ crypto_data_extractor/  # CÃ³digo da funÃ§Ã£o Lambda para coleta dos dados
â”‚   â”œâ”€â”€ lambda_layer                          # Pacote com dependÃªncias da Lambda em formato .zip
â”‚   â”‚   â””â”€â”€ lambda_dependencies_layer.zip     # Arquivo com bibliotecas utilizadas pela Lambda
â”‚   â”œâ”€â”€ src                                   # CÃ³digo-fonte do extrator
â”‚   â”‚   â”œâ”€â”€ crawler
â”‚   â”‚   â”‚   â””â”€â”€ fetcher.py                    # Script principal responsÃ¡vel pela extraÃ§Ã£o de dados via API
â”‚   â”‚   â””â”€â”€ __init__.py                       # Inicializador de mÃ³dulo Python
â”‚   â”œâ”€â”€ lambda_function_code.zip              # CÃ³digo empacotado da funÃ§Ã£o Lambda para deploy
â”‚   â””â”€â”€ requirements.txt                      # Lista de dependÃªncias da aplicaÃ§Ã£o
â”œâ”€â”€ docs/                   # Prints de tela e vÃ­deos com evidÃªncias de execuÃ§Ã£o
â”œâ”€â”€ lakehouse/              # Notebooks e scripts relacionados ao Databricks
â”‚   â”œâ”€â”€ 01.bronze                            # Processamento da camada Bronze
â”‚   â”‚   â”œâ”€â”€ processaDiario.ipynb             # Processa dados diÃ¡rios dos criptoativos para Delta Bronze
â”‚   â”‚   â””â”€â”€ processaHistorico.ipynb          # Processa dados histÃ³ricos dos criptoativos para Delta Bronze
â”‚   â”œâ”€â”€ 02.silver                            # Processamento da camada Silver
â”‚   â”‚   â””â”€â”€ processamentoDominioCripto.ipynb # UnificaÃ§Ã£o de dados em uma tabela Silver para o domÃ­nio de criptoativos
â”‚   â””â”€â”€ 03.gold                              # GeraÃ§Ã£o de visÃµes analÃ­ticas (Gold)
â”‚       â””â”€â”€ visoesDominioCripto.ipynb        # VisÃµes analÃ­ticas sobre os ativos para possÃ­veis anÃ¡lises futuras
â””â”€â”€ README.md               # Este arquivo com a descriÃ§Ã£o geral do projeto

```

---

## ğŸ“… FrequÃªncia de Coleta

- DiÃ¡ria (via AWS Lambda)
- Endpoints utilizados: `/coins/{id}/market_chart`, entre outros da [CoinGecko API](https://www.coingecko.com/en/api)

---

## ğŸ§ª Como Executar Localmente

1. Clone o repositÃ³rio:

```bash
git clone https://github.com/douglas-engenheirodedados/mvpEngDadosPosPuc
cd crypto_data_extractor
```

2. Crie um ambiente virtual e instale as dependÃªncias:

```bash
python -m venv venv
source venv/bin/activate  # ou venv\Scripts\activate no Windows
pip install -r requirements.txt
```

3. Execute o script de coleta manualmente (opcional):

```bash
python src/crawler/fetcher #adequar os endpoints da API e S3 para o seu contexto.
```

---

## ğŸ§¾ LicenÃ§a dos Dados

Este projeto utiliza dados pÃºblicos disponibilizados pela [CoinGecko API](https://www.coingecko.com/en/api), sob seus termos de uso.

---

## âœ… Checklist para Entrega

âœ… Objetivo e perguntas de negÃ³cio definidos

âœ… Coleta automÃ¡tica implementada

âœ… Modelagem e catÃ¡logo de dados

âœ… Pipeline de dados com Databricks

âœ… AnÃ¡lise de dados (qualidade + soluÃ§Ã£o)

âœ… AutoavaliaÃ§Ã£o escrita

âœ… EvidÃªncias (prints e/ou vÃ­deos) adicionadas em docs/

âœ… CÃ³digo hospedado em repositÃ³rio pÃºblico do GitHub

---

## âœï¸ Autor

- **Nome:** Douglas Littig
- **Curso:** PÃ³s-graduaÃ§Ã£o em CiÃªncia de Dados e Analitycs